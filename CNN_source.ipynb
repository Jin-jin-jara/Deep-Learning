{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_source.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpA5vXltx6n+srrkpdq+7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jin-jin-jara/Deep-Learning/blob/master/CNN_source.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnFElgQrrpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 파일이 있으면 지우고 새로운 파일 만들기\n",
        "!rm -rf imagenet\n",
        "!mkdir imagenet\n",
        "\n",
        "!rm -rf dogs.tar.gz\n",
        "!ls -al  \n",
        "\n",
        "# 압축 풀기\n",
        "!tar xvfz dogs.tar.gz\n",
        "!ls -al dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6eMa1njrscd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 다운 받아 가져오기\n",
        "# 버섯\n",
        "!wget -O imagenet/mushroom1.jpg http://farm4.static.flickr.com/3023/2822584107_186167ff68.jpg\n",
        "!wget -O imagenet/mushroom2.jpg http://farm3.static.flickr.com/2416/1593642808_efcef6c9c2.jpg\n",
        "!wget -O imagenet/mushroom3.jpg http://farm4.static.flickr.com/3003/2536991564_5f9b2f5b53.jpg\n",
        "  \n",
        "# 강아지\n",
        "!wget -O imagenet/dog1.jpg http://farm1.static.flickr.com/58/160964915_d708f48d0d.jpg\n",
        "!wget -O imagenet/dog2.jpg http://farm1.static.flickr.com/51/144906086_049df05364.jpg\n",
        "!wget -O imagenet/dog3.jpg http://farm3.static.flickr.com/2133/2236535445_ca650757f2.jpg\n",
        "  \n",
        "# 고양이  \n",
        "!wget -O imagenet/cat1.jpg http://farm1.static.flickr.com/131/393656824_bd89c512d0.jpg\n",
        "!wget -O imagenet/cat2.jpg http://farm1.static.flickr.com/213/505539125_d7193beb76.jpg\n",
        "!wget -O imagenet/cat3.jpg http://farm1.static.flickr.com/24/63785988_c16c10b4e5.jpg\n",
        "\n",
        "!wget https://github.com/dhrim/bmac_seminar/raw/master/material/dogs.tar.gz\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyXoJ8aMrse1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN을 위한 라이브러리 가져오기\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications import vgg16\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwFsN1ivrsg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지 데이터 로드하고 넘파이로 변환하고 등등 케라스에서도 제공하지만 수동으로 해야할 경우\n",
        "def load_file_names_and_category_names(path):\n",
        "  \n",
        "  file_names = []\n",
        "  category_names = []\n",
        "\n",
        "  dir_names = os.listdir(path)\n",
        "      \n",
        "  for dir_name in dir_names:\n",
        "    file_names_in_a_dir = os.listdir(path+\"/\"+dir_name)\n",
        "\n",
        "    for a_file_name in file_names_in_a_dir:\n",
        "      full_file_name = path+\"/\"+dir_name+\"/\"+a_file_name\n",
        "      file_names.append(full_file_name)\n",
        "      category_names.append(dir_name)\n",
        "\n",
        "  return file_names, category_names\n",
        "\n",
        "\n",
        "def load_image_files_into_numpy_array(file_names):\n",
        "  file_count = len(file_names)    \n",
        "  data = np.ndarray(shape=(file_count,224,224,3), dtype=np.float64)    \n",
        "  for i in range(len(file_names)):\n",
        "    image = load_img(file_names[i], target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    data[i] = image\n",
        "  return data\n",
        "\n",
        "\n",
        "def load_custom_data(path, train_ratio=0.8):\n",
        "  \n",
        "  file_names, category_names = load_file_names_and_category_names(path)\n",
        "  x = load_image_files_into_numpy_array(file_names)\n",
        "  \n",
        "  labels, y = np.unique(category_names, return_inverse=True)  \n",
        "\n",
        "  s = int(x.shape[0]*train_ratio)\n",
        "  train_x, test_x = x[:s], x[s:]\n",
        "  train_y, test_y = y[:s], y[s:]\n",
        "  \n",
        "  return (train_x, train_y), (test_x, test_y), labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eETsWv8rsjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y), custom_labels = load_custom_data(\"dogs\")\n",
        "\n",
        "train_x = vgg16.preprocess_input(train_x)\n",
        "test_x = vgg16.preprocess_input(test_x)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n",
        "print(custom_labels)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_BgykMPrslM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_x[0])\n",
        "print(train_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4graAcYrsnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기존에 학습된 모델 파일 삭제\n",
        "vgg16_model_path = 'new_trained_from_vgg16.h5'\n",
        "!rm -rf {vgg16_model_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9FwdoLPrspd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# from tensorflow.keras.applications import vgg16\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import resnet50   # 모듈이름\n",
        "from tensorflow.keras.applications import ResNet50   # 클래스 이름\n",
        "\n",
        "\n",
        "# conv_layers = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "conv_layers = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # 뒤에 densenet부분이 top 즉 include_top=False라면 feature extraction부분만 쓰겠다는 의미\n",
        "# Convolution Layer를 학습되지 않도록 고정 (실제 vgg와 테스크가 다르니까 다르게 써야하는데, 이미 학습이 잘 된 모델을 가져왔으니까 convolution쪽은 학습하지마 그대로 쓸거니까)\n",
        "conv_layers.trainable = False\n",
        "\n",
        "# 새로운 모델 생성하기\n",
        "model = models.Sequential()\n",
        "\n",
        "# VGG16모델의 Convolution Layer를 추가\n",
        "# 여긴 trainable이 False니까 학습이 안되고\n",
        "model.add(conv_layers)\n",
        "\n",
        "# 여기가 학습되는 부분\n",
        "# 모델의 Fully Connected 부분을 재구성\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# 모델\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "\n",
        "\n",
        "data_aug_generator = ImageDataGenerator(   # train 데이터 증강 제너레이터\n",
        "      rotation_range=10,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "#       preprocessing_function=vgg16.preprocess_input\n",
        "      preprocessing_function=resnet50.preprocess_input # 여기에 preprocess 함수를 설정\n",
        ")\n",
        "\n",
        "\n",
        "data_no_aug_generator = ImageDataGenerator(   # test는 증강시킬 필요 없으니까 no_aug\n",
        "#       preprocessing_function=vgg16.preprocess_input\n",
        "      preprocessing_function=resnet50.preprocess_input\n",
        ")\n",
        "\n",
        "# flow_from_directory 메소드를 활용하면 폴더 형태로된 데이터 구조를 바로 가져와서 사용할 수 있다.\n",
        "train_data_generator = data_aug_generator.flow_from_directory(  # 이 디렉토리에 있는 데이터를 증강시켜라\n",
        "      \"dogs_prepared/train\",\n",
        "      target_size=(224,224),\n",
        "      batch_size=64,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data_generator = data_no_aug_generator.flow_from_directory(  # 증강시킬 필요 없고 \n",
        "      \"dogs_prepared/test\",\n",
        "      target_size=(224,224),\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "# 여기선 fit이 아니라 fit_generator를 쓴다\n",
        "model.fit_generator(\n",
        "      train_data_generator,\n",
        "      validation_data=test_data_generator,\n",
        "      validation_steps=5,       # 매 에포크마다 벨리데이션\n",
        "      steps_per_epoch=train_data_generator.samples/64,  # data_size / batch_size\n",
        "      epochs=10\n",
        ")\n",
        "\n",
        "# model.fit(train_x, train_y, epochs=100, batch_size=64, shuffle=True, validation_split=0.1)\n",
        "\n",
        "# 모델 저장하기\n",
        "model.save(vgg16_model_path)\n",
        "\n",
        "y_ = model.predict_generator(\n",
        "      test_data_generator,\n",
        "      steps=test_data_generator.samples/64\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0z87nfUrsrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 결과 확인 \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss =\",loss)\n",
        "print(\"acc =\",acc)\n",
        "\n",
        "custom_labels = list(test_data_generator.class_indices.keys())\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "print(predicted[0], custom_labels[predicted[0]])\n",
        "\n",
        "# train_x, test_x는 vgg16.prerprocess_input()에 의해 변형되었다.\n",
        "(_, _), (raw_test_x, _), custom_labels = load_custom_data(\"dogs\")\n",
        "\n",
        "\n",
        "for i in [0,50,100,150,200]:  \n",
        "  print(test_y[i], custom_labels[test_y[i]])\n",
        "  print(predicted[i], custom_labels[predicted[i]])\n",
        "  plt.imshow(raw_test_x[i].astype(int))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LTa_M3_rstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5P7oGySrsv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keryn9uJrsyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cllJ6R3rs0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6-Zmmamrs2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjDVIInrs4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5CMAanors69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ms_YVdrs9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x1vupd9rs_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0f10ym8rtB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}